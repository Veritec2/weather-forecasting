{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c127229",
   "metadata": {},
   "source": [
    "# Iterative Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32808f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Ensure plots display inline in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "train_inputs_tensor = t.load('f:/weather_forecasting/notebooks/final project/tensors/train_inputs_norm.pt').to(device)\n",
    "train_targets_tensor = t.load('f:/weather_forecasting/notebooks/final project/tensors/train_targets_norm.pt').to(device)\n",
    "print(f\"Tensors loaded: train inputs {train_inputs_tensor.shape}, train targets {train_targets_tensor.shape}\")\n",
    "print(f\"Normalized t2m_f mean: {train_targets_tensor[:, :, 5, :].mean().item():.2f}, std: {train_targets_tensor[:, :, 5, :].std().item():.2f}\")\n",
    "\n",
    "# Temporary Train/Test split\n",
    "train_size = int(0.9 * train_inputs_tensor.shape[0])\n",
    "print(f\"Train size: {train_size}\")\n",
    "temp_train_inputs = train_inputs_tensor[:train_size]\n",
    "temp_train_targets = train_targets_tensor[:train_size]\n",
    "temp_test_inputs = train_inputs_tensor[train_size:]\n",
    "temp_test_targets = train_targets_tensor[train_size:]\n",
    "print(f\"Train/test split: train shape {temp_train_inputs.shape}, test shape {temp_test_inputs.shape}\")\n",
    "\n",
    "# Move tensors to GPU upfront\n",
    "temp_train_inputs = temp_train_inputs.to(device)\n",
    "temp_train_targets = temp_train_targets.to(device)\n",
    "temp_test_inputs = temp_test_inputs.to(device)\n",
    "temp_test_targets = temp_test_targets.to(device)\n",
    "\n",
    "# Define grid and edge index (must match training setup)\n",
    "num_nodes = 23937\n",
    "k = 8\n",
    "lat_subset = np.linspace(50, 25, 101)\n",
    "lon_subset = np.linspace(235, 294, 237)\n",
    "coords = np.stack(np.meshgrid(lat_subset, lon_subset, indexing='ij'), axis=-1).reshape(-1, 2)\n",
    "nbrs = NearestNeighbors(n_neighbors=k+1).fit(coords)\n",
    "_, indices = nbrs.kneighbors(coords)\n",
    "edge_index = t.tensor(np.stack([np.repeat(np.arange(num_nodes), k), indices[:, 1:].flatten()]), dtype=t.long).to(device)\n",
    "\n",
    "# Model definition (must match the trained model)\n",
    "class WeatherGNN(t.nn.Module):\n",
    "    def __init__(self, num_features=15, hidden_dims=128, num_outputs=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dims)\n",
    "        self.conv2 = GCNConv(hidden_dims, hidden_dims)\n",
    "        self.conv3 = GCNConv(hidden_dims, num_outputs)\n",
    "        self.dropout = t.nn.Dropout(0.3)\n",
    "        self.residual = t.nn.Linear(num_features, num_outputs)\n",
    "        self.res_weight = t.nn.Parameter(t.tensor(2.0))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        residual = self.residual(x) * self.res_weight\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x + residual\n",
    "\n",
    "# Define L1 loss function directly\n",
    "def l1_loss(x, y):\n",
    "    return t.mean(t.abs(x - y))\n",
    "\n",
    "# Pre-compute t2m_f statistics for denormalization (must match training)\n",
    "t2m_f_mean = 42.36  # °F\n",
    "t2m_f_std = 21.75   # °F\n",
    "\n",
    "# Testing function with iterative predictions\n",
    "def test_model_iterative(model_path, inputs_tensor, targets_tensor, edge_index, num_nodes, device, t2m_f_mean, t2m_f_std, lat_subset, lon_subset):\n",
    "    model = WeatherGNN(num_features=15, hidden_dims=128, num_outputs=1).to(device)\n",
    "    model.load_state_dict(t.load(model_path))\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "    # Validate inputs\n",
    "    print(f\"Inputs tensor shape: {inputs_tensor.shape}\")\n",
    "    print(f\"Targets tensor shape: {targets_tensor.shape}\")\n",
    "    if inputs_tensor.shape[0] < 2 or targets_tensor.shape[0] < 2:\n",
    "        raise ValueError(\"Input and target tensors must have at least 2 time steps for prediction.\")\n",
    "\n",
    "    # Iterative prediction\n",
    "    test_preds = []\n",
    "    current_input = inputs_tensor[0].clone()  # Shape: [num_nodes, num_features, 1]\n",
    "    t2m_f_idx = 0  # Index of t2m_f in the feature dimension (after dropping t2m, d2m, d2m_f, t)\n",
    "\n",
    "    for t_step in range(inputs_tensor.shape[0] - 1):\n",
    "        # Reshape input for the model\n",
    "        input_x = current_input.reshape(num_nodes, -1)  # Shape: [num_nodes, num_features]\n",
    "        \n",
    "        # Predict t2m_f for the next time step\n",
    "        with t.no_grad():\n",
    "            out = model(input_x, edge_index)  # Shape: [num_nodes, 1]\n",
    "        test_preds.append(out)\n",
    "\n",
    "        # Prepare input for the next time step\n",
    "        if t_step < inputs_tensor.shape[0] - 2:\n",
    "            # Use true inputs for all features except t2m_f\n",
    "            current_input = inputs_tensor[t_step + 1].clone()  # Shape: [num_nodes, num_features, 1]\n",
    "            # Replace the t2m_f feature with the normalized prediction\n",
    "            normalized_pred = (out - t2m_f_mean) / t2m_f_std  # Shape: [num_nodes, 1]\n",
    "            current_input[:, t2m_f_idx, 0] = normalized_pred.squeeze(-1)  # Shape: [num_nodes]\n",
    "\n",
    "    test_preds = t.stack(test_preds)  # Shape: [num_time_steps-1, num_nodes, 1], on GPU\n",
    "    test_trues = targets_tensor[:-1, :, 5, :].reshape(targets_tensor.shape[0]-1, num_nodes, 1)  # Shape: [num_time_steps-1, num_nodes, 1], on GPU\n",
    "\n",
    "    # Denormalize for evaluation and plotting\n",
    "    preds_t2m = test_preds * t2m_f_std + t2m_f_mean  # On GPU\n",
    "    trues_t2m = test_trues * t2m_f_std + t2m_f_mean  # On GPU\n",
    "    mae_t2m = t.mean(t.abs(preds_t2m - trues_t2m)).item()\n",
    "    rmse_t2m = t.sqrt(t.mean((preds_t2m - trues_t2m) ** 2)).item()\n",
    "    print(f\"Iterative t2m_f L1 norm (°F): {mae_t2m:.2f}\")\n",
    "    print(f\"Iterative t2m_f RMSE (°F): {rmse_t2m:.2f}\")\n",
    "\n",
    "    # Move to CPU for plotting\n",
    "    preds_t2m = preds_t2m.cpu()\n",
    "    trues_t2m = trues_t2m.cpu()\n",
    "\n",
    "    # Plot variation at specific nodes in subplots\n",
    "    nodes_to_plot = [0, 236, 8926, 23500]  # Example: NW, NE, Central, SW\n",
    "    node_labels = ['NW (Node 0)', 'NE (Node 236)', 'Central (Node 8926)', 'SW (Node 23500)']\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    for idx, node, label in zip(range(len(nodes_to_plot)), nodes_to_plot, node_labels):\n",
    "        ax = axes[idx]\n",
    "        ax.plot(preds_t2m[:, node, 0].numpy(), label='Iterative Pred', linestyle='--', color='red')\n",
    "        ax.plot(trues_t2m[:, node, 0].numpy(), label='True', linestyle='-', color='green')\n",
    "        ax.set_xlabel('Time Step')\n",
    "        ax.set_ylabel('Temperature (°F)')\n",
    "        ax.set_title(f'Iterative Predicted vs True t2m_f at {label}')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('t2m_f_iterative_variation_nodes_subplots.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Debug and plot spatial difference for first time step with lat/lon grid overlay\n",
    "    first_pred = preds_t2m[0, :, 0].numpy()\n",
    "    first_true = trues_t2m[0, :, 0].numpy()\n",
    "    print(f\"First predicted t2m_f shape: {first_pred.shape}\")\n",
    "    print(f\"First true t2m_f shape: {first_true.shape}\")\n",
    "    print(f\"First predicted t2m_f sample: {first_pred[:5]}\")\n",
    "    print(f\"First true t2m_f sample: {first_true[:5]}\")\n",
    "\n",
    "    # Check for NaN or infinite values\n",
    "    if np.any(np.isnan(first_pred)) or np.any(np.isnan(first_true)):\n",
    "        raise ValueError(\"NaN values detected in predictions or true values.\")\n",
    "    if np.any(np.isinf(first_pred)) or np.any(np.isinf(first_true)):\n",
    "        raise ValueError(\"Infinite values detected in predictions or true values.\")\n",
    "\n",
    "    diff = np.abs(first_pred - first_true)\n",
    "    print(f\"Difference min: {np.min(diff):.2f}, max: {np.max(diff):.2f}, mean: {np.mean(diff):.2f}\")\n",
    "\n",
    "    # Reshape difference to 2D grid\n",
    "    if diff.shape[0] != num_nodes:\n",
    "        raise ValueError(f\"Expected {num_nodes} nodes, but got {diff.shape[0]}\")\n",
    "    if len(lat_subset) * len(lon_subset) != num_nodes:\n",
    "        raise ValueError(f\"Grid size mismatch: lat_subset ({len(lat_subset)}) * lon_subset ({len(lon_subset)}) != num_nodes ({num_nodes})\")\n",
    "    diff_grid = diff.reshape(len(lat_subset), len(lon_subset))\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    contour = plt.contourf(lon_subset, lat_subset, diff_grid, cmap='RdBu_r', levels=np.linspace(0, max(np.max(diff), 1), 21), alpha=0.8)\n",
    "    plt.colorbar(label='Absolute Difference (°F)')\n",
    "    \n",
    "    # Overlay latitude and longitude grid lines\n",
    "    plt.grid(True, linestyle='--', color='gray', alpha=0.3)  # Subtle grid lines\n",
    "    plt.xticks(ticks=np.linspace(min(lon_subset), max(lon_subset), 10), rotation=45)\n",
    "    plt.yticks(ticks=np.linspace(min(lat_subset), max(lat_subset), 10))\n",
    "    \n",
    "    plt.title('Iterative Absolute Difference (Pred - True) for t2m_f at First Test Time Step')\n",
    "    plt.xlabel('Longitude (°E)')\n",
    "    plt.ylabel('Latitude (°N)')\n",
    "    save_path = 't2m_f_iterative_grid_difference.png'\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Spatial grid plot saved to: {os.path.abspath(save_path)}\")\n",
    "    plt.show()\n",
    "\n",
    "# Run the test with iterative predictions\n",
    "test_model_iterative(\n",
    "    model_path=r'F:\\weather_forecasting\\notebooks\\final project\\models\\Final Model\\final_model_ext_training.pth',\n",
    "    inputs_tensor=temp_test_inputs,\n",
    "    targets_tensor=temp_test_targets,\n",
    "    edge_index=edge_index,\n",
    "    num_nodes=num_nodes,\n",
    "    device=device,\n",
    "    t2m_f_mean=t2m_f_mean,\n",
    "    t2m_f_std=t2m_f_std,\n",
    "    lat_subset=lat_subset,\n",
    "    lon_subset=lon_subset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821bf0ce",
   "metadata": {},
   "source": [
    "# Specifying Testing at Major Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f24716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Ensure plots display inline in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "train_inputs_tensor = t.load('f:/weather_forecasting/notebooks/final project/tensors/train_inputs_norm.pt').to(device)\n",
    "train_targets_tensor = t.load('f:/weather_forecasting/notebooks/final project/tensors/train_targets_norm.pt').to(device)\n",
    "print(f\"Tensors loaded: train inputs {train_inputs_tensor.shape}, train targets {train_targets_tensor.shape}\")\n",
    "print(f\"Normalized t2m_f mean: {train_targets_tensor[:, :, 5, :].mean().item():.2f}, std: {train_targets_tensor[:, :, 5, :].std().item():.2f}\")\n",
    "\n",
    "# Temporary Train/Test split\n",
    "train_size = int(0.9 * train_inputs_tensor.shape[0])\n",
    "print(f\"Train size: {train_size}\")\n",
    "temp_train_inputs = train_inputs_tensor[:train_size]\n",
    "temp_train_targets = train_targets_tensor[:train_size]\n",
    "temp_test_inputs = train_inputs_tensor[train_size:]\n",
    "temp_test_targets = train_targets_tensor[train_size:]\n",
    "print(f\"Train/test split: train shape {temp_train_inputs.shape}, test shape {temp_test_inputs.shape}\")\n",
    "\n",
    "# Move tensors to GPU upfront\n",
    "temp_train_inputs = temp_train_inputs.to(device)\n",
    "temp_train_targets = temp_train_targets.to(device)\n",
    "temp_test_inputs = temp_test_inputs.to(device)\n",
    "temp_test_targets = temp_test_targets.to(device)\n",
    "\n",
    "# Define grid and edge index (must match training setup)\n",
    "num_nodes = 23937\n",
    "k = 8\n",
    "lat_subset = np.linspace(50, 25, 101)\n",
    "lon_subset = np.linspace(235, 294, 237)\n",
    "coords = np.stack(np.meshgrid(lat_subset, lon_subset, indexing='ij'), axis=-1).reshape(-1, 2)\n",
    "nbrs = NearestNeighbors(n_neighbors=k+1).fit(coords)\n",
    "_, indices = nbrs.kneighbors(coords)\n",
    "edge_index = t.tensor(np.stack([np.repeat(np.arange(num_nodes), k), indices[:, 1:].flatten()]), dtype=t.long).to(device)\n",
    "\n",
    "# Model definition (must match the trained model)\n",
    "class WeatherGNN(t.nn.Module):\n",
    "    def __init__(self, num_features=15, hidden_dims=128, num_outputs=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dims)\n",
    "        self.conv2 = GCNConv(hidden_dims, hidden_dims)\n",
    "        self.conv3 = GCNConv(hidden_dims, num_outputs)\n",
    "        self.dropout = t.nn.Dropout(0.3)\n",
    "        self.residual = t.nn.Linear(num_features, num_outputs)\n",
    "        self.res_weight = t.nn.Parameter(t.tensor(2.0))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        residual = self.residual(x) * self.res_weight\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x + residual\n",
    "\n",
    "# Define L1 loss function directly\n",
    "def l1_loss(x, y):\n",
    "    return t.mean(t.abs(x - y))\n",
    "\n",
    "# Pre-compute t2m_f statistics for denormalization\n",
    "t2m_f_mean = 42.36  # °F\n",
    "t2m_f_std = 21.75   # °F\n",
    "\n",
    "# Define cities and their node indices\n",
    "cities_nodes = [\n",
    "    (\"Los Angeles\", 15195),\n",
    "    (\"San Francisco\", 11623),\n",
    "    (\"Seattle\", 2381),\n",
    "    (\"Missoula\", 2888),\n",
    "    (\"Salt Lake City\", 8821),\n",
    "    (\"Denver\", 9797),\n",
    "    (\"Phoenix\", 15694),\n",
    "    (\"San Antonio\", 19540),\n",
    "    (\"New Orleans\", 19100),\n",
    "    (\"Kansas City, MO\", 10570),\n",
    "    (\"Chicago\", 7733),\n",
    "    (\"New York City\", 8973),\n",
    "    (\"Boston\", 7563),\n",
    "    (\"Philadelphia\", 9679),\n",
    "    (\"Atlanta\", 15567),\n",
    "    (\"Miami\", 23188),\n",
    "]\n",
    "\n",
    "# Testing function with iterative predictions\n",
    "def test_model_iterative(model_path, inputs_tensor, targets_tensor, edge_index, num_nodes, device, t2m_f_mean, t2m_f_std, lat_subset, lon_subset):\n",
    "    model = WeatherGNN(num_features=15, hidden_dims=128, num_outputs=1).to(device)\n",
    "    model.load_state_dict(t.load(model_path))\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "    # Validate inputs\n",
    "    print(f\"Inputs tensor shape: {inputs_tensor.shape}\")\n",
    "    print(f\"Targets tensor shape: {targets_tensor.shape}\")\n",
    "    if inputs_tensor.shape[0] < 2 or targets_tensor.shape[0] < 2:\n",
    "        raise ValueError(\"Input and target tensors must have at least 2 time steps for prediction.\")\n",
    "\n",
    "    # Iterative prediction\n",
    "    test_preds = []\n",
    "    current_input = inputs_tensor[0].clone()  # Shape: [num_nodes, num_features, 1]\n",
    "    t2m_f_idx = 0  # Index of t2m_f in the feature dimension\n",
    "\n",
    "    for t_step in range(inputs_tensor.shape[0] - 1):\n",
    "        input_x = current_input.reshape(num_nodes, -1)  # Shape: [num_nodes, num_features]\n",
    "        with t.no_grad():\n",
    "            out = model(input_x, edge_index)  # Shape: [num_nodes, 1]\n",
    "        test_preds.append(out)\n",
    "        if t_step < inputs_tensor.shape[0] - 2:\n",
    "            current_input = inputs_tensor[t_step + 1].clone()\n",
    "            normalized_pred = (out - t2m_f_mean) / t2m_f_std\n",
    "            current_input[:, t2m_f_idx, 0] = normalized_pred.squeeze(-1)\n",
    "\n",
    "    test_preds = t.stack(test_preds)  # Shape: [num_time_steps-1, num_nodes, 1]\n",
    "    test_trues = targets_tensor[:-1, :, 5, :].reshape(targets_tensor.shape[0]-1, num_nodes, 1)\n",
    "\n",
    "    # Denormalize for evaluation and plotting\n",
    "    preds_t2m = test_preds * t2m_f_std + t2m_f_mean\n",
    "    trues_t2m = test_trues * t2m_f_std + t2m_f_mean\n",
    "    mae_t2m = t.mean(t.abs(preds_t2m - trues_t2m)).item()\n",
    "    rmse_t2m = t.sqrt(t.mean((preds_t2m - trues_t2m) ** 2)).item()\n",
    "    print(f\"Iterative t2m_f L1 norm (°F): {mae_t2m:.2f}\")\n",
    "    print(f\"Iterative t2m_f RMSE (°F): {rmse_t2m:.2f}\")\n",
    "\n",
    "    # Move to CPU for plotting\n",
    "    preds_t2m = preds_t2m.cpu()\n",
    "    trues_t2m = trues_t2m.cpu()\n",
    "\n",
    "    # Plot variation at specific cities in subplots\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for idx, (city, node) in enumerate(cities_nodes):\n",
    "        ax = axes[idx]\n",
    "        ax.plot(preds_t2m[:, node, 0].numpy(), label='Iterative Pred', linestyle='--', color='red')\n",
    "        ax.plot(trues_t2m[:, node, 0].numpy(), label='True', linestyle='-', color='green')\n",
    "        ax.set_xlabel('Time Step')\n",
    "        ax.set_ylabel('Temperature (°F)')\n",
    "        ax.set_title(f'{city}')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('t2m_f_iterative_variation_cities_subplots.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Debug and plot spatial difference for first time step\n",
    "    first_pred = preds_t2m[0, :, 0].numpy()\n",
    "    first_true = trues_t2m[0, :, 0].numpy()\n",
    "    print(f\"First predicted t2m_f shape: {first_pred.shape}\")\n",
    "    print(f\"First true t2m_f shape: {first_true.shape}\")\n",
    "    print(f\"First predicted t2m_f sample: {first_pred[:5]}\")\n",
    "    print(f\"First true t2m_f sample: {first_true[:5]}\")\n",
    "\n",
    "    # Check for NaN or infinite values\n",
    "    if np.any(np.isnan(first_pred)) or np.any(np.isnan(first_true)):\n",
    "        raise ValueError(\"NaN values detected in predictions or true values.\")\n",
    "    if np.any(np.isinf(first_pred)) or np.any(np.isinf(first_true)):\n",
    "        raise ValueError(\"Infinite values detected in predictions or true values.\")\n",
    "\n",
    "    diff = np.abs(first_pred - first_true)\n",
    "    print(f\"Difference min: {np.min(diff):.2f}, max: {np.max(diff):.2f}, mean: {np.mean(diff):.2f}\")\n",
    "\n",
    "    # Reshape difference to 2D grid\n",
    "    if diff.shape[0] != num_nodes:\n",
    "        raise ValueError(f\"Expected {num_nodes} nodes, but got {diff.shape[0]}\")\n",
    "    if len(lat_subset) * len(lon_subset) != num_nodes:\n",
    "        raise ValueError(f\"Grid size mismatch: lat_subset ({len(lat_subset)}) * lon_subset ({len(lon_subset)}) != num_nodes ({num_nodes})\")\n",
    "    diff_grid = diff.reshape(len(lat_subset), len(lon_subset))\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    contour = plt.contourf(lon_subset, lat_subset, diff_grid, cmap='Blues', levels=np.linspace(0, max(np.max(diff), 1), 21), alpha=0.8)\n",
    "    plt.colorbar(label='Absolute Difference (°F)')\n",
    "    # Overlay darker latitude and longitude grid lines\n",
    "    plt.grid(True, linestyle='--', color='black', alpha=0.7)\n",
    "    plt.xticks(ticks=np.linspace(min(lon_subset), max(lon_subset), 10), rotation=45)\n",
    "    plt.yticks(ticks=np.linspace(min(lat_subset), max(lat_subset), 10))\n",
    "    plt.title('Iterative Absolute Difference (Pred - True) for t2m_f at First Test Time Step')\n",
    "    plt.xlabel('Longitude (°E)')\n",
    "    plt.ylabel('Latitude (°N)')\n",
    "    save_path = 't2m_f_iterative_grid_difference.png'\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Spatial grid plot saved to: {os.path.abspath(save_path)}\")\n",
    "    plt.show()\n",
    "\n",
    "# Run the test with iterative predictions\n",
    "test_model_iterative(\n",
    "    model_path=r'F:\\weather_forecasting\\notebooks\\final project\\models\\Final Model\\final_model_ext_training.pth',\n",
    "    inputs_tensor=temp_test_inputs,\n",
    "    targets_tensor=temp_test_targets,\n",
    "    edge_index=edge_index,\n",
    "    num_nodes=num_nodes,\n",
    "    device=device,\n",
    "    t2m_f_mean=t2m_f_mean,\n",
    "    t2m_f_std=t2m_f_std,\n",
    "    lat_subset=lat_subset,\n",
    "    lon_subset=lon_subset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9915a84",
   "metadata": {},
   "source": [
    "# Testing all 8 models using iterative approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# Ensure plots display inline in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Directories\n",
    "model_dir = r'F:\\weather_forecasting\\notebooks\\final project\\models\\paths'\n",
    "png_dir = r'F:\\weather_forecasting\\notebooks\\final project\\png'\n",
    "\n",
    "# Load tensors\n",
    "train_inputs_tensor = t.load('f:/weather_forecasting/notebooks/final project/tensors/train_inputs_norm.pt').to(device)\n",
    "train_targets_tensor = t.load('f:/weather_forecasting/notebooks/final project/tensors/train_targets_norm.pt').to(device)\n",
    "print(f\"Tensors loaded: train inputs {train_inputs_tensor.shape}, train targets {train_targets_tensor.shape}\")\n",
    "print(f\"Normalized t2m_f mean: {train_targets_tensor[:, :, 5, :].mean().item():.2f}, std: {train_targets_tensor[:, :, 5, :].std().item():.2f}\")\n",
    "\n",
    "# Temporary Train/Test split\n",
    "train_size = int(0.9 * train_inputs_tensor.shape[0])\n",
    "print(f\"Train size: {train_size}\")\n",
    "temp_train_inputs = train_inputs_tensor[:train_size]\n",
    "temp_train_targets = train_targets_tensor[:train_size]\n",
    "temp_test_inputs = train_inputs_tensor[train_size:]\n",
    "temp_test_targets = train_targets_tensor[train_size:]\n",
    "print(f\"Train/test split: train shape {temp_train_inputs.shape}, test shape {temp_test_inputs.shape}\")\n",
    "\n",
    "# Move tensors to GPU upfront\n",
    "temp_train_inputs = temp_train_inputs.to(device)\n",
    "temp_train_targets = temp_train_targets.to(device)\n",
    "temp_test_inputs = temp_test_inputs.to(device)\n",
    "temp_test_targets = temp_test_targets.to(device)\n",
    "\n",
    "# Define grid and edge index\n",
    "num_nodes = 23937\n",
    "k = 8\n",
    "lat_subset = np.linspace(50, 25, 101)\n",
    "lon_subset = np.linspace(235, 294, 237)\n",
    "coords = np.stack(np.meshgrid(lat_subset, lon_subset, indexing='ij'), axis=-1).reshape(-1, 2)\n",
    "nbrs = NearestNeighbors(n_neighbors=k+1).fit(coords)\n",
    "_, indices = nbrs.kneighbors(coords)\n",
    "edge_index = t.tensor(np.stack([np.repeat(np.arange(num_nodes), k), indices[:, 1:].flatten()]), dtype=t.long).to(device)\n",
    "\n",
    "# Model definition\n",
    "class WeatherGNN(t.nn.Module):\n",
    "    def __init__(self, num_features=15, hidden_dims=128, num_outputs=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dims)\n",
    "        self.conv2 = GCNConv(hidden_dims, hidden_dims)\n",
    "        self.conv3 = GCNConv(hidden_dims, num_outputs)\n",
    "        self.dropout = t.nn.Dropout(0.3)\n",
    "        self.residual = t.nn.Linear(num_features, num_outputs)\n",
    "        self.res_weight = t.nn.Parameter(t.tensor(2.0))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        residual = self.residual(x) * self.res_weight\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x + residual\n",
    "\n",
    "# Define L1 loss function\n",
    "def l1_loss(x, y):\n",
    "    return t.mean(t.abs(x - y))\n",
    "\n",
    "# Pre-compute t2m_f statistics for denormalization\n",
    "t2m_f_mean = 42.36  # °F\n",
    "t2m_f_std = 21.75   # °F\n",
    "\n",
    "# Compute node indices for 16 major U.S. cities\n",
    "cities = [\n",
    "    (\"Los Angeles\", 34.05, -118.24),\n",
    "    (\"San Francisco\", 37.77, -122.42),\n",
    "    (\"Seattle\", 47.61, -122.33),\n",
    "    (\"Missoula\", 46.87, -113.99),\n",
    "    (\"Salt Lake City\", 40.76, -111.89),\n",
    "    (\"Denver\", 39.74, -104.99),\n",
    "    (\"Phoenix\", 33.45, -112.07),\n",
    "    (\"San Antonio\", 29.42, -98.49),\n",
    "    (\"New Orleans\", 29.95, -90.07),\n",
    "    (\"Kansas City\", 39.10, -94.58),\n",
    "    (\"Chicago\", 41.88, -87.63),\n",
    "    (\"New York City\", 40.71, -74.01),\n",
    "    (\"Boston\", 42.36, -71.06),\n",
    "    (\"Philadelphia\", 39.95, -75.17),\n",
    "    (\"Atlanta\", 33.75, -84.39),\n",
    "    (\"Miami\", 25.76, -80.19)\n",
    "]\n",
    "\n",
    "nodes_to_plot = []\n",
    "node_labels = []\n",
    "for city, lat, lon in cities:\n",
    "    # Convert longitude to 0-360 range\n",
    "    lon = lon if lon > 0 else 360 + lon\n",
    "    # Find nearest latitude and longitude indices\n",
    "    lat_idx = np.argmin(np.abs(lat_subset - lat))\n",
    "    lon_idx = np.argmin(np.abs(lon_subset - lon))\n",
    "    # Compute node index\n",
    "    node_idx = (lat_idx * 237) + lon_idx\n",
    "    nodes_to_plot.append(node_idx)\n",
    "    node_labels.append(city)\n",
    "    print(f\"{city}: Lat {lat:.2f}°N, Lon {lon:.2f}°E -> Node {node_idx} (Lat idx: {lat_idx}, Lon idx: {lon_idx})\")\n",
    "\n",
    "# Testing function with iterative predictions\n",
    "def test_model_iterative(model_path, inputs_tensor, targets_tensor, edge_index, num_nodes, device, t2m_f_mean, t2m_f_std, lat_subset, lon_subset, plot_suffix=''):\n",
    "    model = WeatherGNN(num_features=15, num_outputs=1).to(device)\n",
    "    model.load_state_dict(t.load(model_path))\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "    # Validate inputs\n",
    "    print(f\"Inputs tensor shape: {inputs_tensor.shape}\")\n",
    "    print(f\"Targets tensor shape: {targets_tensor.shape}\")\n",
    "    if inputs_tensor.shape[0] < 2 or targets_tensor.shape[0] < 2:\n",
    "        raise ValueError(\"Input and target tensors must have at least 2 time steps for prediction.\")\n",
    "\n",
    "    # Iterative prediction\n",
    "    test_preds = []\n",
    "    current_input = inputs_tensor[0].clone()  # Shape: [num_nodes, num_features, 1]\n",
    "    t2m_f_idx = 0  # Index of t2m_f in the feature dimension\n",
    "\n",
    "    for t_step in range(inputs_tensor.shape[0] - 1):\n",
    "        input_x = current_input.reshape(num_nodes, -1)  # Shape: [num_nodes, num_features]\n",
    "        with t.no_grad():\n",
    "            out = model(input_x, edge_index)  # Shape: [num_nodes, 1]\n",
    "        test_preds.append(out)\n",
    "\n",
    "        if t_step < inputs_tensor.shape[0] - 2:\n",
    "            current_input = inputs_tensor[t_step + 1].clone()\n",
    "            normalized_pred = (out - t2m_f_mean) / t2m_f_std\n",
    "            current_input[:, t2m_f_idx, 0] = normalized_pred.squeeze(-1)\n",
    "\n",
    "    test_preds = t.stack(test_preds)\n",
    "    test_trues = targets_tensor[:-1, :, 5, :].reshape(targets_tensor.shape[0]-1, num_nodes, 1)\n",
    "\n",
    "    preds_t2m = test_preds * t2m_f_std + t2m_f_mean\n",
    "    trues_t2m = test_trues * t2m_f_std + t2m_f_mean\n",
    "    mae_t2m = t.mean(t.abs(preds_t2m - trues_t2m)).item()\n",
    "    rmse_t2m = t.sqrt(t.mean((preds_t2m - trues_t2m) ** 2)).item()\n",
    "    print(f\"Iterative t2m_f L1 norm (°F): {mae_t2m:.2f}\")\n",
    "    print(f\"Iterative t2m_f RMSE (°F): {rmse_t2m:.2f}\")\n",
    "\n",
    "    preds_t2m = preds_t2m.cpu()\n",
    "    trues_t2m = trues_t2m.cpu()\n",
    "\n",
    "    # Plot variation at specific cities in subplots\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for idx, node, city in zip(range(len(nodes_to_plot)), nodes_to_plot, node_labels):\n",
    "        ax = axes[idx]\n",
    "        ax.plot(preds_t2m[:, node, 0].numpy(), label='Iterative Pred', linestyle='--', color='red')\n",
    "        ax.plot(trues_t2m[:, node, 0].numpy(), label='True', linestyle='-', color='green')\n",
    "        ax.set_xlabel('Time Step')\n",
    "        ax.set_ylabel('Temperature (°F)')\n",
    "        ax.set_title(f'Predicted vs True t2m_f at {city}')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(png_dir, f't2m_f_iterative_variation_cities_subplots_{plot_suffix}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot spatial difference with U.S. outline\n",
    "    first_pred = preds_t2m[0, :, 0].numpy()\n",
    "    first_true = trues_t2m[0, :, 0].numpy()\n",
    "    diff = np.abs(first_pred - first_true)\n",
    "    diff_grid = diff.reshape(len(lat_subset), len(lon_subset))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    contour = ax.contourf(lon_subset, lat_subset, diff_grid, cmap='Pastel1', levels=np.linspace(0, max(np.max(diff), 1), 21), transform=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.STATES.with_scale('10m'), edgecolor='black', linewidth=0.5)\n",
    "    plt.colorbar(contour, label='Absolute Difference (°F)')\n",
    "    ax.set_title('Iterative Absolute Difference (Pred - True) for t2m_f at First Test Time Step')\n",
    "    ax.set_xlabel('Longitude (°E)')\n",
    "    ax.set_ylabel('Latitude (°N)')\n",
    "    save_path = os.path.join(png_dir, f't2m_f_iterative_grid_difference_{plot_suffix}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "# Model files\n",
    "model_files = [\n",
    "    'model_lr0p001_adaptive_20250418_083926.pth',\n",
    "    'model_lr0p001_stationary_20250418_083926.pth',\n",
    "    'model_lr0p01_adaptive_20250418_083926.pth',\n",
    "    'model_lr0p01_stationary_20250418_083926.pth',\n",
    "    'model_lr0p0005_adaptive_20250418_083926.pth',\n",
    "    'model_lr0p0005_stationary_20250418_083926.pth',\n",
    "    'model_lr0p005_adaptive_20250418_083926.pth',\n",
    "    'model_lr0p005_stationary_20250418_083926.pth'\n",
    "]\n",
    "\n",
    "# Loop over each model\n",
    "for model_file in model_files:\n",
    "    print(f\"\\nRunning iterative predictions for model: {model_file}\")\n",
    "    model_id = os.path.basename(model_file).replace('.pth', '')\n",
    "    test_model_iterative(\n",
    "        model_path=os.path.join(model_dir, model_file),\n",
    "        inputs_tensor=temp_test_inputs,\n",
    "        targets_tensor=temp_test_targets,\n",
    "        edge_index=edge_index,\n",
    "        num_nodes=num_nodes,\n",
    "        device=device,\n",
    "        t2m_f_mean=t2m_f_mean,\n",
    "        t2m_f_std=t2m_f_std,\n",
    "        lat_subset=lat_subset,\n",
    "        lon_subset=lon_subset,\n",
    "        plot_suffix=model_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b0420",
   "metadata": {},
   "source": [
    "# Final Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082fc01",
   "metadata": {},
   "source": [
    "## Processing April Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Ensure plots display inline in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# File paths\n",
    "file_path_test_a = \"../nc/accum_test.nc\"\n",
    "file_path_test_i = \"../nc/instant_test.nc\"\n",
    "file_path_test_p = \"../nc/pressure_test.nc\"\n",
    "\n",
    "# Open datasets with larger chunks\n",
    "# Testing Data [April 1, 2025 - April 7, 2025]\n",
    "start = time.time()\n",
    "ds_a_test = xr.open_dataset(file_path_test_a, chunks={'valid_time': 100})\n",
    "ds_i_test = xr.open_dataset(file_path_test_i, chunks={'valid_time': 100})\n",
    "ds_p_test = xr.open_dataset(file_path_test_p, chunks={'valid_time':100})\n",
    "# Drop expver if present\n",
    "if 'expver' in ds_a_test.coords:\n",
    "    ds_a_train = ds_a_test.drop_vars('expver')\n",
    "if 'expver' in ds_i_test.coords:\n",
    "    ds_i_train = ds_i_test.drop_vars('expver')\n",
    "if 'expver' in ds_p_test.coords:\n",
    "    ds_p_train = ds_p_test.drop_vars('expver')\n",
    "print(f\"Testing datasets opened in {time.time() - start:.2f}s: ds_i_test shape {ds_i_test.dims}, ds_a_test shape {ds_a_test.dims}, ds_p_test shape {ds_p_test.dims}\")\n",
    "\n",
    "# Define variable names\n",
    "i_vars = ['t2m', 'd2m', 'tcc', 'sp', 'u10', 'v10', 'stl1', 'blh']\n",
    "a_vars = ['tp', 'sshf', 'slhf', 'ssrd', 'strd']\n",
    "p_vars = ['t', 'q']\n",
    "print(f\"Variables defined: instant {i_vars}, accum {a_vars}, pressure {p_vars}\")\n",
    "\n",
    "# Merge datasets\n",
    "# Testing Data\n",
    "start = time.time()\n",
    "ds_test_merge = xr.merge([ds_i_test[i_vars], ds_a_test[a_vars], ds_p_test[p_vars]])\n",
    "print(f\"Testing datasets merged in {time.time() - start:.2f}s: shape {ds_test_merge.dims}, dtype {ds_test_merge[i_vars[0]].dtype}\")\n",
    "\n",
    "# Convert to Fahrenheit\n",
    "def kelvin_to_fahrenheit(temp_k):\n",
    "    temp_f = (temp_k - 273.15) * 9/5 + 32\n",
    "    return temp_f\n",
    "\n",
    "# Converting to fahrenheit & adding temperature spread\n",
    "start = time.time()\n",
    "ds_test_merge = ds_test_merge.assign(t2m_f=lambda ds: kelvin_to_fahrenheit(ds['t2m']))\n",
    "ds_test_merge = ds_test_merge.assign(d2m_f=lambda ds: kelvin_to_fahrenheit(ds['d2m']))\n",
    "ds_test_merge = ds_test_merge.assign(t_f=lambda ds: kelvin_to_fahrenheit(ds['t']))\n",
    "ds_test_merge = ds_test_merge.assign(t_spread_f=lambda ds: ds['t2m_f']-ds['d2m_f'])\n",
    "print(f\"Converting to F in {time.time() - start:.2f}\")\n",
    "\n",
    "# Dropping the original temperature variables as well as d2m_f\n",
    "ds_test_merge = ds_test_merge.drop_vars(['t2m', 'd2m', 'd2m_f', 't'])\n",
    "\n",
    "# Update variables\n",
    "i_vars = ['t2m_f', 't_spread_f', 'tcc', 'sp', 'u10', 'v10', 'stl1', 'blh']\n",
    "a_vars = ['tp', 'sshf', 'slhf', 'ssrd', 'strd']\n",
    "p_vars = ['t_f', 'q']\n",
    "all_vars = a_vars+i_vars+p_vars\n",
    "\n",
    "# Save intermediates\n",
    "start = time.time()\n",
    "ds_test_merge.to_netcdf('f:/weather_forecasting/ds_train.nc')\n",
    "print(f\"Saved intermediates in {time.time() - start:.2f}s: test shape {ds_test_merge.dims}\")\n",
    "\n",
    "# Stack spatial dimensions\n",
    "start = time.time()\n",
    "ds_test_stacked = ds_test_merge[all_vars].stack(node=('latitude', 'longitude'))\n",
    "print(f\"Stacked spatial dims in {time.time() - start:.2f}s: test shape {ds_test_stacked.dims}\")\n",
    "\n",
    "# Create inputs and targets (all time steps)\n",
    "start = time.time()\n",
    "# Testing\n",
    "total_test_time_steps = ds_test_stacked.dims['valid_time']\n",
    "print(f\"Total testing time steps: {total_test_time_steps}\")\n",
    "test_inputs = ds_test_stacked.isel(valid_time=slice(0, total_test_time_steps - 1))\n",
    "test_targets = ds_test_stacked.isel(valid_time=slice(1, total_test_time_steps))\n",
    "\n",
    "# Tensor build\n",
    "# Convert to numpy array\n",
    "start = time.time()\n",
    "test_inputs_array = test_inputs.to_array().values.transpose(1, 2, 0, 3)\n",
    "test_targets_array = test_targets.to_array().values.transpose(1, 2, 0, 3)\n",
    "print(f\"Converted to arrays in {time.time() - start:.2f}s: test inputs shape {test_inputs_array.shape}, test targets shape {test_targets_array.shape}, dtype {test_inputs_array.dtype}\")\n",
    "\n",
    "# Convert to pytorch tensors\n",
    "start = time.time()\n",
    "test_inputs_tensor = t.tensor(test_inputs_array, dtype=t.float32).to(device)\n",
    "test_targets_tensor = t.tensor(test_targets_array, dtype=t.float32).to(device)\n",
    "print(f\"Tensors built in {time.time() - start:.2f}s: test inputs shape {test_inputs_tensor.shape}, test targets shape {test_targets_tensor.shape}, device {test_inputs_tensor.device}\")\n",
    "\n",
    "# Normalize tensors (using mean and std from the testing dataset only)\n",
    "start = time.time()\n",
    "test_inputs_mean = test_inputs_tensor.mean(dim=(0, 1), keepdim=True)\n",
    "test_inputs_std = test_inputs_tensor.std(dim=(0, 1), keepdim=True)\n",
    "test_targets_mean = test_targets_tensor.mean(dim=(0, 1), keepdim=True)\n",
    "test_targets_std = test_targets_tensor.std(dim=(0, 1), keepdim=True)\n",
    "\n",
    "# Normalize testing tensors\n",
    "test_inputs_tensor = (test_inputs_tensor - test_inputs_mean) / (test_inputs_std + 1e-8)\n",
    "test_targets_tensor = (test_targets_tensor - test_targets_mean) / (test_targets_std + 1e-8)\n",
    "\n",
    "# Save normalized tensors\n",
    "start = time.time()\n",
    "t.save(test_inputs_tensor.cpu(), 'f:/weather_forecasting/notebooks/final project/tensors/test_inputs_norm.pt')\n",
    "t.save(test_targets_tensor.cpu(), 'f:/weather_forecasting/notebooks/final project/tensors/test_targets_norm.pt')\n",
    "print(f\"Normalized tensors saved in {time.time() - start:.2f}s to f:/weather_forecasting/notebooks/final project/tensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e460d5e0",
   "metadata": {},
   "source": [
    "## Testing Against Persistence Model Using Processed April Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b73d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Ensure plots display inline in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "test_inputs_tensor = t.load('f:/weather_forecasting/notebooks/final project/tensors/test_inputs_norm.pt').to(device)\n",
    "test_targets_tensor = t.load('f:/weather_forecasting/notebooks/final project/tensors/test_targets_norm.pt').to(device)\n",
    "print(f\"Tensors loaded: test inputs {test_inputs_tensor.shape}, test targets {test_targets_tensor.shape}\")\n",
    "print(f\"Normalized t2m_f mean: {test_targets_tensor[:, :, 5, :].mean().item():.2f}, std: {test_targets_tensor[:, :, 5, :].std().item():.2f}\")\n",
    "\n",
    "# Define grid and edge index (must match training setup)\n",
    "num_nodes = 23937\n",
    "k = 8\n",
    "lat_subset = np.linspace(50, 25, 101)\n",
    "lon_subset = np.linspace(235, 294, 237)\n",
    "coords = np.stack(np.meshgrid(lat_subset, lon_subset, indexing='ij'), axis=-1).reshape(-1, 2)\n",
    "nbrs = NearestNeighbors(n_neighbors=k+1).fit(coords)\n",
    "_, indices = nbrs.kneighbors(coords)\n",
    "edge_index = t.tensor(np.stack([np.repeat(np.arange(num_nodes), k), indices[:, 1:].flatten()]), dtype=t.long).to(device)\n",
    "\n",
    "# Model definition (must match the trained model)\n",
    "class WeatherGNN(t.nn.Module):\n",
    "    def __init__(self, num_features=15, hidden_dims=128, num_outputs=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dims)\n",
    "        self.conv2 = GCNConv(hidden_dims, hidden_dims)\n",
    "        self.conv3 = GCNConv(hidden_dims, num_outputs)\n",
    "        self.dropout = t.nn.Dropout(0.3)\n",
    "        self.residual = t.nn.Linear(num_features, num_outputs)\n",
    "        self.res_weight = t.nn.Parameter(t.tensor(2.0))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        residual = self.residual(x) * self.res_weight\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x + residual\n",
    "\n",
    "# Define L1 loss function directly\n",
    "def l1_loss(x, y):\n",
    "    return t.mean(t.abs(x - y))\n",
    "\n",
    "# Pre-compute t2m_f statistics for denormalization (must match training)\n",
    "t2m_f_mean = 42.36  # °F\n",
    "t2m_f_std = 21.75   # °F\n",
    "\n",
    "# Define cities and their node indices\n",
    "cities_nodes = [\n",
    "    (\"Los Angeles\", 15195),\n",
    "    (\"San Francisco\", 11623),\n",
    "    (\"Seattle\", 2381),\n",
    "    (\"Missoula\", 2888),\n",
    "    (\"Salt Lake City\", 8821),\n",
    "    (\"Denver\", 9797),\n",
    "    (\"Phoenix\", 15694),\n",
    "    (\"San Antonio\", 19540),\n",
    "    (\"New Orleans\", 19100),\n",
    "    (\"Kansas City, MO\", 10570),\n",
    "    (\"Chicago\", 7733),\n",
    "    (\"New York City\", 8973),\n",
    "    (\"Boston\", 7563),\n",
    "    (\"Philadelphia\", 9679),\n",
    "    (\"Atlanta\", 15567),\n",
    "    (\"Miami\", 23188),\n",
    "]\n",
    "\n",
    "# Testing function with iterative predictions and corrected persistence model\n",
    "def test_model_iterative(model_path, inputs_tensor, targets_tensor, edge_index, num_nodes, device, t2m_f_mean, t2m_f_std, lat_subset, lon_subset):\n",
    "    model = WeatherGNN(num_features=15, hidden_dims=128, num_outputs=1).to(device)\n",
    "    model.load_state_dict(t.load(model_path))\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "    # Validate inputs\n",
    "    print(f\"Inputs tensor shape: {inputs_tensor.shape}\")\n",
    "    print(f\"Targets tensor shape: {targets_tensor.shape}\")\n",
    "    if inputs_tensor.shape[0] < 2 or targets_tensor.shape[0] < 2:\n",
    "        raise ValueError(\"Input and target tensors must have at least 2 time steps for prediction.\")\n",
    "\n",
    "    # Iterative prediction for GNN model\n",
    "    test_preds = []\n",
    "    current_input = inputs_tensor[0].clone()  # Shape: [num_nodes, num_features, 1]\n",
    "    t2m_f_idx = 0  # Index of t2m_f in the feature dimension\n",
    "\n",
    "    # Persistence model: predict all future steps as the value at time 0\n",
    "    test_persist_preds = []\n",
    "    persist_pred = targets_tensor[0, :, 5, :].reshape(1, num_nodes, 1)  # Value at t=0, Shape: [1, num_nodes, 1]\n",
    "\n",
    "    for t_step in range(inputs_tensor.shape[0] - 1):\n",
    "        input_x = current_input.reshape(num_nodes, -1)  # Shape: [num_nodes, num_features]\n",
    "        with t.no_grad():\n",
    "            out = model(input_x, edge_index)  # Shape: [num_nodes, 1]\n",
    "        test_preds.append(out)\n",
    "        test_persist_preds.append(persist_pred.squeeze(0))  # Use t=0 value for all predictions\n",
    "        if t_step < inputs_tensor.shape[0] - 2:\n",
    "            current_input = inputs_tensor[t_step + 1].clone()\n",
    "            normalized_pred = (out - t2m_f_mean) / t2m_f_std\n",
    "            current_input[:, t2m_f_idx, 0] = normalized_pred.squeeze(-1)\n",
    "\n",
    "    test_preds = t.stack(test_preds)  # Shape: [num_time_steps-1, num_nodes, 1]\n",
    "    test_persist_preds = t.stack(test_persist_preds)  # Shape: [num_time_steps-1, num_nodes, 1]\n",
    "    test_trues = targets_tensor[1:, :, 5, :].reshape(targets_tensor.shape[0]-1, num_nodes, 1)  # True values for t=1 to T-1\n",
    "\n",
    "    # Denormalize for evaluation and plotting\n",
    "    preds_t2m = test_preds * t2m_f_std + t2m_f_mean\n",
    "    persist_t2m = test_persist_preds * t2m_f_std + t2m_f_mean\n",
    "    trues_t2m = test_trues * t2m_f_std + t2m_f_mean\n",
    "    mae_t2m = t.mean(t.abs(preds_t2m - trues_t2m)).item()\n",
    "    rmse_t2m = t.sqrt(t.mean((preds_t2m - trues_t2m) ** 2)).item()\n",
    "    persist_mae_t2m = t.mean(t.abs(persist_t2m - trues_t2m)).item()\n",
    "    persist_rmse_t2m = t.sqrt(t.mean((persist_t2m - trues_t2m) ** 2)).item()\n",
    "    print(f\"GNN Iterative t2m_f L1 norm (°F): {mae_t2m:.2f}\")\n",
    "    print(f\"GNN Iterative t2m_f RMSE (°F): {rmse_t2m:.2f}\")\n",
    "    print(f\"Persistence t2m_f L1 norm (°F): {persist_mae_t2m:.2f}\")\n",
    "    print(f\"Persistence t2m_f RMSE (°F): {persist_rmse_t2m:.2f}\")\n",
    "\n",
    "    # Move to CPU for plotting\n",
    "    preds_t2m = preds_t2m.cpu()\n",
    "    persist_t2m = persist_t2m.cpu()\n",
    "    trues_t2m = trues_t2m.cpu()\n",
    "\n",
    "    # Plot variation at specific cities in subplots with persistence\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for idx, (city, node) in enumerate(cities_nodes):\n",
    "        ax = axes[idx]\n",
    "        ax.plot(preds_t2m[:, node, 0].numpy(), label='GNN Pred', linestyle='--', color='red')\n",
    "        ax.plot(persist_t2m[:, node, 0].numpy(), label='Persistence Pred', linestyle=':', color='blue')\n",
    "        ax.plot(trues_t2m[:, node, 0].numpy(), label='True', linestyle='-', color='green')\n",
    "        ax.set_xlabel('Time Step')\n",
    "        ax.set_ylabel('Temperature (°F)')\n",
    "        ax.set_title(f'{city}')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('t2m_f_iterative_variation_cities_subplots_with_persistence.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Debug and plot spatial difference for first time step\n",
    "    first_pred = preds_t2m[0, :, 0].numpy()\n",
    "    first_true = trues_t2m[0, :, 0].numpy()\n",
    "    print(f\"First predicted t2m_f shape: {first_pred.shape}\")\n",
    "    print(f\"First true t2m_f shape: {first_true.shape}\")\n",
    "    print(f\"First predicted t2m_f sample: {first_pred[:5]}\")\n",
    "    print(f\"First true t2m_f sample: {first_true[:5]}\")\n",
    "\n",
    "    diff = np.abs(first_pred - first_true)\n",
    "    print(f\"Difference min: {np.min(diff):.2f}, max: {np.max(diff):.2f}, mean: {np.mean(diff):.2f}\")\n",
    "\n",
    "    # Reshape difference to 2D grid\n",
    "    if diff.shape[0] != num_nodes:\n",
    "        raise ValueError(f\"Expected {num_nodes} nodes, but got {diff.shape[0]}\")\n",
    "    if len(lat_subset) * len(lon_subset) != num_nodes:\n",
    "        raise ValueError(f\"Grid size mismatch: lat_subset ({len(lat_subset)}) * lon_subset ({len(lon_subset)}) != num_nodes ({num_nodes})\")\n",
    "    diff_grid = diff.reshape(len(lat_subset), len(lon_subset))\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    contour = plt.contourf(lon_subset, lat_subset, diff_grid, cmap='Pastel1', levels=np.linspace(0, max(np.max(diff), 1), 21), alpha=0.8)\n",
    "    plt.colorbar(label='Absolute Difference (°F)')\n",
    "    # Overlay darker latitude and longitude grid lines\n",
    "    plt.grid(True, linestyle='--', color='black', alpha=0.7)\n",
    "    plt.xticks(ticks=np.linspace(min(lon_subset), max(lon_subset), 10), rotation=45)\n",
    "    plt.yticks(ticks=np.linspace(min(lat_subset), max(lat_subset), 10))\n",
    "    plt.title('GNN Iterative Absolute Difference (Pred - True) for t2m_f at First Test Time Step')\n",
    "    plt.xlabel('Longitude (°E)')\n",
    "    plt.ylabel('Latitude (°N)')\n",
    "    save_path = 't2m_f_iterative_grid_difference.png'\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Spatial grid plot saved to: {os.path.abspath(save_path)}\")\n",
    "    plt.show()\n",
    "\n",
    "# Run the test with iterative predictions\n",
    "test_model_iterative(\n",
    "    model_path=r'f:\\weather_forecasting\\notebooks\\final project\\models\\Final Model\\final_model.pth',\n",
    "    inputs_tensor=test_inputs_tensor,\n",
    "    targets_tensor=test_targets_tensor,\n",
    "    edge_index=edge_index,\n",
    "    num_nodes=num_nodes,\n",
    "    device=device,\n",
    "    t2m_f_mean=t2m_f_mean,\n",
    "    t2m_f_std=t2m_f_std,\n",
    "    lat_subset=lat_subset,\n",
    "    lon_subset=lon_subset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Ensure plots display inline in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "test_inputs_tensor = t.load('f:/weather_forecasting/notebooks/final project/tensors/test_inputs_norm.pt').to(device)\n",
    "test_targets_tensor = t.load('f:/weather_forecasting/notebooks/final project/tensors/test_targets_norm.pt').to(device)\n",
    "print(f\"Tensors loaded: test inputs {test_inputs_tensor.shape}, test targets {test_targets_tensor.shape}\")\n",
    "print(f\"Normalized t2m_f mean: {test_targets_tensor[:, :, 5, :].mean().item():.2f}, std: {test_targets_tensor[:, :, 5, :].std().item():.2f}\")\n",
    "\n",
    "# Define grid and edge index (must match training setup)\n",
    "num_nodes = 23937\n",
    "k = 8\n",
    "lat_subset = np.linspace(50, 25, 101)\n",
    "lon_subset = np.linspace(235, 294, 237)\n",
    "coords = np.stack(np.meshgrid(lat_subset, lon_subset, indexing='ij'), axis=-1).reshape(-1, 2)\n",
    "nbrs = NearestNeighbors(n_neighbors=k+1).fit(coords)\n",
    "_, indices = nbrs.kneighbors(coords)\n",
    "edge_index = t.tensor(np.stack([np.repeat(np.arange(num_nodes), k), indices[:, 1:].flatten()]), dtype=t.long).to(device)\n",
    "\n",
    "# Model definition (must match the trained model)\n",
    "class WeatherGNN(t.nn.Module):\n",
    "    def __init__(self, num_features=15, hidden_dims=128, num_outputs=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dims)\n",
    "        self.conv2 = GCNConv(hidden_dims, hidden_dims)\n",
    "        self.conv3 = GCNConv(hidden_dims, num_outputs)\n",
    "        self.dropout = t.nn.Dropout(0.3)\n",
    "        self.residual = t.nn.Linear(num_features, num_outputs)\n",
    "        self.res_weight = t.nn.Parameter(t.tensor(2.0))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        residual = self.residual(x) * self.res_weight\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x + residual\n",
    "\n",
    "# Define L1 loss function directly\n",
    "def l1_loss(x, y):\n",
    "    return t.mean(t.abs(x - y))\n",
    "\n",
    "# Pre-compute t2m_f statistics for denormalization (must match training)\n",
    "t2m_f_mean = 42.36  # °F\n",
    "t2m_f_std = 21.75   # °F\n",
    "\n",
    "# Define cities and their node indices\n",
    "cities_nodes = [\n",
    "    (\"Los Angeles\", 15195),\n",
    "    (\"San Francisco\", 11623),\n",
    "    (\"Seattle\", 2381),\n",
    "    (\"Missoula\", 2888),\n",
    "    (\"Salt Lake City\", 8821),\n",
    "    (\"Denver\", 9797),\n",
    "    (\"Phoenix\", 15694),\n",
    "    (\"San Antonio\", 19540),\n",
    "    (\"New Orleans\", 19100),\n",
    "    (\"Kansas City, MO\", 10570),\n",
    "    (\"Chicago\", 7733),\n",
    "    (\"New York City\", 8973),\n",
    "    (\"Boston\", 7563),\n",
    "    (\"Philadelphia\", 9679),\n",
    "    (\"Atlanta\", 15567),\n",
    "    (\"Miami\", 23188),\n",
    "]\n",
    "\n",
    "# Testing function with iterative predictions and corrected persistence model\n",
    "def test_model_iterative(model_path, inputs_tensor, targets_tensor, edge_index, num_nodes, device, t2m_f_mean, t2m_f_std, lat_subset, lon_subset):\n",
    "    model = WeatherGNN(num_features=15, hidden_dims=128, num_outputs=1).to(device)\n",
    "    model.load_state_dict(t.load(model_path))\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "    # Validate inputs\n",
    "    print(f\"Inputs tensor shape: {inputs_tensor.shape}\")\n",
    "    print(f\"Targets tensor shape: {targets_tensor.shape}\")\n",
    "    if inputs_tensor.shape[0] < 2 or targets_tensor.shape[0] < 2:\n",
    "        raise ValueError(\"Input and target tensors must have at least 2 time steps for prediction.\")\n",
    "\n",
    "    # Iterative prediction for GNN model\n",
    "    test_preds = []\n",
    "    current_input = inputs_tensor[0].clone()  # Shape: [num_nodes, num_features, 1]\n",
    "    t2m_f_idx = 0  # Index of t2m_f in the feature dimension\n",
    "\n",
    "    # Persistence model: predict all future steps as the value at time 0\n",
    "    test_persist_preds = []\n",
    "    persist_pred = targets_tensor[0, :, 5, :].reshape(1, num_nodes, 1)  # Value at t=0, Shape: [1, num_nodes, 1]\n",
    "\n",
    "    for t_step in range(inputs_tensor.shape[0] - 1):\n",
    "        input_x = current_input.reshape(num_nodes, -1)  # Shape: [num_nodes, num_features]\n",
    "        with t.no_grad():\n",
    "            out = model(input_x, edge_index)  # Shape: [num_nodes, 1]\n",
    "        test_preds.append(out)\n",
    "        test_persist_preds.append(persist_pred.squeeze(0))  # Use t=0 value for all predictions\n",
    "        if t_step < inputs_tensor.shape[0] - 2:\n",
    "            current_input = inputs_tensor[t_step + 1].clone()\n",
    "            normalized_pred = (out - t2m_f_mean) / t2m_f_std\n",
    "            current_input[:, t2m_f_idx, 0] = normalized_pred.squeeze(-1)\n",
    "\n",
    "    test_preds = t.stack(test_preds)  # Shape: [num_time_steps-1, num_nodes, 1]\n",
    "    test_persist_preds = t.stack(test_persist_preds)  # Shape: [num_time_steps-1, num_nodes, 1]\n",
    "    test_trues = targets_tensor[1:, :, 5, :].reshape(targets_tensor.shape[0]-1, num_nodes, 1)  # True values for t=1 to T-1\n",
    "\n",
    "    # Denormalize for evaluation and plotting\n",
    "    preds_t2m = test_preds * t2m_f_std + t2m_f_mean\n",
    "    persist_t2m = test_persist_preds * t2m_f_std + t2m_f_mean\n",
    "    trues_t2m = test_trues * t2m_f_std + t2m_f_mean\n",
    "    mae_t2m = t.mean(t.abs(preds_t2m - trues_t2m)).item()\n",
    "    rmse_t2m = t.sqrt(t.mean((preds_t2m - trues_t2m) ** 2)).item()\n",
    "    persist_mae_t2m = t.mean(t.abs(persist_t2m - trues_t2m)).item()\n",
    "    persist_rmse_t2m = t.sqrt(t.mean((persist_t2m - trues_t2m) ** 2)).item()\n",
    "    print(f\"GNN Iterative t2m_f L1 norm (°F): {mae_t2m:.2f}\")\n",
    "    print(f\"GNN Iterative t2m_f RMSE (°F): {rmse_t2m:.2f}\")\n",
    "    print(f\"Persistence t2m_f L1 norm (°F): {persist_mae_t2m:.2f}\")\n",
    "    print(f\"Persistence t2m_f RMSE (°F): {persist_rmse_t2m:.2f}\")\n",
    "\n",
    "    # Move to CPU for plotting\n",
    "    preds_t2m = preds_t2m.cpu()\n",
    "    persist_t2m = persist_t2m.cpu()\n",
    "    trues_t2m = trues_t2m.cpu()\n",
    "\n",
    "    # Plot variation at specific cities in subplots with persistence\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for idx, (city, node) in enumerate(cities_nodes):\n",
    "        ax = axes[idx]\n",
    "        ax.plot(preds_t2m[:, node, 0].numpy(), label='GNN Pred', linestyle='--', color='red')\n",
    "        ax.plot(persist_t2m[:, node, 0].numpy(), label='Persistence Pred', linestyle=':', color='blue')\n",
    "        ax.plot(trues_t2m[:, node, 0].numpy(), label='True', linestyle='-', color='green')\n",
    "        ax.set_xlabel('Time Step')\n",
    "        ax.set_ylabel('Temperature (°F)')\n",
    "        ax.set_title(f'{city}')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('t2m_f_iterative_variation_cities_subplots_with_persistence.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Debug and plot spatial difference for first time step\n",
    "    first_pred = preds_t2m[0, :, 0].numpy()\n",
    "    first_true = trues_t2m[0, :, 0].numpy()\n",
    "    print(f\"First predicted t2m_f shape: {first_pred.shape}\")\n",
    "    print(f\"First true t2m_f shape: {first_true.shape}\")\n",
    "    print(f\"First predicted t2m_f sample: {first_pred[:5]}\")\n",
    "    print(f\"First true t2m_f sample: {first_true[:5]}\")\n",
    "\n",
    "    diff = np.abs(first_pred - first_true)\n",
    "    print(f\"Difference min: {np.min(diff):.2f}, max: {np.max(diff):.2f}, mean: {np.mean(diff):.2f}\")\n",
    "\n",
    "    # Reshape difference to 2D grid\n",
    "    if diff.shape[0] != num_nodes:\n",
    "        raise ValueError(f\"Expected {num_nodes} nodes, but got {diff.shape[0]}\")\n",
    "    if len(lat_subset) * len(lon_subset) != num_nodes:\n",
    "        raise ValueError(f\"Grid size mismatch: lat_subset ({len(lat_subset)}) * lon_subset ({len(lon_subset)}) != num_nodes ({num_nodes})\")\n",
    "    diff_grid = diff.reshape(len(lat_subset), len(lon_subset))\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    contour = plt.contourf(lon_subset, lat_subset, diff_grid, cmap='Pastel1', levels=np.linspace(0, max(np.max(diff), 1), 21), alpha=0.8)\n",
    "    plt.colorbar(label='Absolute Difference (°F)')\n",
    "    # Overlay darker latitude and longitude grid lines\n",
    "    plt.grid(True, linestyle='--', color='black', alpha=0.7)\n",
    "    plt.xticks(ticks=np.linspace(min(lon_subset), max(lon_subset), 10), rotation=45)\n",
    "    plt.yticks(ticks=np.linspace(min(lat_subset), max(lat_subset), 10))\n",
    "    plt.title('GNN Iterative Absolute Difference (Pred - True) for t2m_f at First Test Time Step')\n",
    "    plt.xlabel('Longitude (°E)')\n",
    "    plt.ylabel('Latitude (°N)')\n",
    "    save_path = 't2m_f_iterative_grid_difference.png'\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Spatial grid plot saved to: {os.path.abspath(save_path)}\")\n",
    "    plt.show()\n",
    "\n",
    "# Run the test with iterative predictions\n",
    "test_model_iterative(\n",
    "    model_path=r'f:\\weather_forecasting\\notebooks\\final project\\models\\Final Model\\final_model_ext_training.pth',\n",
    "    inputs_tensor=test_inputs_tensor,\n",
    "    targets_tensor=test_targets_tensor,\n",
    "    edge_index=edge_index,\n",
    "    num_nodes=num_nodes,\n",
    "    device=device,\n",
    "    t2m_f_mean=t2m_f_mean,\n",
    "    t2m_f_std=t2m_f_std,\n",
    "    lat_subset=lat_subset,\n",
    "    lon_subset=lon_subset\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
